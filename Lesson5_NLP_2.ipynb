{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import jieba\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"C:/study/AI Training and Jobs/NLP_CV_Course/datasource-master/export_sql_1558435/sqlResult_1558435.csv\"\n",
    "stop_words_path = \"C:/study/AI Training and Jobs/NLP_CV_Course/datasource-master/\"\n",
    "cleaned_data_path = \"C:/study/AI Training and Jobs/NLP_CV_Course/week_7/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv(csv_path, encoding='gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "      <th>feature</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>快科技@http://www.kkj.cn/</td>\n",
       "      <td>此外，自本周（6月12日）起，除小米手机6等15款机型外，其余机型已暂停更新发布（含开发版/...</td>\n",
       "      <td>{\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"37\"...</td>\n",
       "      <td>小米MIUI 9首批机型曝光：共计15款</td>\n",
       "      <td>http://www.cnbeta.com/articles/tech/623597.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>快科技@http://www.kkj.cn/</td>\n",
       "      <td>骁龙835作为唯一通过Windows 10桌面平台认证的ARM处理器，高通强调，不会因为只考...</td>\n",
       "      <td>{\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"15\"...</td>\n",
       "      <td>骁龙835在Windows 10上的性能表现有望改善</td>\n",
       "      <td>http://www.cnbeta.com/articles/tech/623599.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>快科技@http://www.kkj.cn/</td>\n",
       "      <td>此前的一加3T搭载的是3400mAh电池，DashCharge快充规格为5V/4A。\\r\\n...</td>\n",
       "      <td>{\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"18\"...</td>\n",
       "      <td>一加手机5细节曝光：3300mAh、充半小时用1天</td>\n",
       "      <td>http://www.cnbeta.com/articles/tech/623601.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>新华社</td>\n",
       "      <td>这是6月18日在葡萄牙中部大佩德罗冈地区拍摄的被森林大火烧毁的汽车。新华社记者张立云摄\\r\\n</td>\n",
       "      <td>{\"type\":\"国际新闻\",\"site\":\"环球\",\"commentNum\":\"0\",\"j...</td>\n",
       "      <td>葡森林火灾造成至少62人死亡 政府宣布进入紧急状态（组图）</td>\n",
       "      <td>http://world.huanqiu.com/hot/2017-06/10866126....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89613</td>\n",
       "      <td>胡淑丽_MN7479</td>\n",
       "      <td>深圳大件事</td>\n",
       "      <td>（原标题：44岁女子跑深圳约会网友被拒，暴雨中裸身奔走……）\\r\\n@深圳交警微博称：昨日清...</td>\n",
       "      <td>{\"type\":\"新闻\",\"site\":\"网易热门\",\"commentNum\":\"978\",...</td>\n",
       "      <td>44岁女子约网友被拒暴雨中裸奔 交警为其披衣相随</td>\n",
       "      <td>http://news.163.com/17/0618/00/CN617P3Q0001875...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      author                  source  \\\n",
       "0  89617         NaN  快科技@http://www.kkj.cn/   \n",
       "1  89616         NaN  快科技@http://www.kkj.cn/   \n",
       "2  89615         NaN  快科技@http://www.kkj.cn/   \n",
       "3  89614         NaN                     新华社   \n",
       "4  89613  胡淑丽_MN7479                   深圳大件事   \n",
       "\n",
       "                                             content  \\\n",
       "0  此外，自本周（6月12日）起，除小米手机6等15款机型外，其余机型已暂停更新发布（含开发版/...   \n",
       "1  骁龙835作为唯一通过Windows 10桌面平台认证的ARM处理器，高通强调，不会因为只考...   \n",
       "2  此前的一加3T搭载的是3400mAh电池，DashCharge快充规格为5V/4A。\\r\\n...   \n",
       "3    这是6月18日在葡萄牙中部大佩德罗冈地区拍摄的被森林大火烧毁的汽车。新华社记者张立云摄\\r\\n   \n",
       "4  （原标题：44岁女子跑深圳约会网友被拒，暴雨中裸身奔走……）\\r\\n@深圳交警微博称：昨日清...   \n",
       "\n",
       "                                             feature  \\\n",
       "0  {\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"37\"...   \n",
       "1  {\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"15\"...   \n",
       "2  {\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"18\"...   \n",
       "3  {\"type\":\"国际新闻\",\"site\":\"环球\",\"commentNum\":\"0\",\"j...   \n",
       "4  {\"type\":\"新闻\",\"site\":\"网易热门\",\"commentNum\":\"978\",...   \n",
       "\n",
       "                           title  \\\n",
       "0           小米MIUI 9首批机型曝光：共计15款   \n",
       "1     骁龙835在Windows 10上的性能表现有望改善   \n",
       "2      一加手机5细节曝光：3300mAh、充半小时用1天   \n",
       "3  葡森林火灾造成至少62人死亡 政府宣布进入紧急状态（组图）   \n",
       "4       44岁女子约网友被拒暴雨中裸奔 交警为其披衣相随   \n",
       "\n",
       "                                                 url  \n",
       "0     http://www.cnbeta.com/articles/tech/623597.htm  \n",
       "1     http://www.cnbeta.com/articles/tech/623599.htm  \n",
       "2     http://www.cnbeta.com/articles/tech/623601.htm  \n",
       "3  http://world.huanqiu.com/hot/2017-06/10866126....  \n",
       "4  http://news.163.com/17/0618/00/CN617P3Q0001875...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 89611 entries, 0 to 89610\n",
      "Data columns (total 7 columns):\n",
      "id         89611 non-null int64\n",
      "author     79396 non-null object\n",
      "source     89609 non-null object\n",
      "content    87054 non-null object\n",
      "feature    89611 non-null object\n",
      "title      89577 non-null object\n",
      "url        87144 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "news.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8778051801676133"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news[news['source'] == '新华社'])/len(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 89611 entries, 0 to 89610\n",
      "Data columns (total 7 columns):\n",
      "id         89611 non-null int64\n",
      "author     79396 non-null object\n",
      "source     89609 non-null object\n",
      "content    87054 non-null object\n",
      "feature    89611 non-null object\n",
      "title      89577 non-null object\n",
      "url        87144 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "news.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.dropna(subset=[\"content\", \"source\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 87052 entries, 0 to 89610\n",
      "Data columns (total 7 columns):\n",
      "id         87052 non-null int64\n",
      "author     76925 non-null object\n",
      "source     87052 non-null object\n",
      "content    87052 non-null object\n",
      "feature    87052 non-null object\n",
      "title      87052 non-null object\n",
      "url        87052 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "news.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanning up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'\\w+')\n",
    "def clean_data(string):\n",
    "    string = re.sub(r'\\d+', 'NUM', string)\n",
    "    words = re.findall(pattern, string)\n",
    "    return ''.join(word for word in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(cleaned_data_path + 'cleaned_data.txt', 'w', encoding='utf-8') as f:\n",
    "    for content in news['content']:\n",
    "        cleaned_content = clean_data(np.str_(content))\n",
    "        f.write(cleaned_content + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jieba 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(string):\n",
    "    return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cleaned_data_path + 'cleaned_data.txt', 'r', encoding='UTF-8') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "with open(stop_words_path + 'chinese_stopwords.txt', 'r', encoding='UTF-8') as f:\n",
    "    stopWords = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine(string):\n",
    "    for stopWord in stopWords:\n",
    "        if stopWord == string:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cleaned_data_path + 'jieba_data.txt', 'w', encoding='UTF-8') as f:\n",
    "    for line in lines:\n",
    "        cuted_words = [cutted_word for cutted_word in cut(line) if determine(cutted_word)]\n",
    "        sentence = ' '.join(t for t in cuted_words)\n",
    "        f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data imbalance Processing using choosen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(cleaned_data_path + 'jieba_data.txt', 'r', encoding='UTF-8') as f:\n",
    "#     lines = f.readlines()\n",
    "# news_pos = news[news['source'].str.contains(\"新华社\")]\n",
    "# news_neg = news[news['source'].str.contains(\"新华社\") == 0]\n",
    "# news_pos = news_pos.sample(len(news_neg))\n",
    "# news_sampled = news_pos.append(news_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Tfidf matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cleaned_data_path + 'jieba_data.txt', 'r', encoding='UTF-8') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.Series(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = ['nba', 'nn', 'nnn', 'nnnum', 'nnum', 'num', 'numnum', 'numn', '一个', '一些', '一名', '一带', '一次', '一直', '一起', '一路', '万元']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus's shape is  (87052,)\n",
      "['nba', 'nn', 'nnn', 'nnnum', 'nnum', 'num', 'numnum', '一个', '一些', '一名', '一带', '一次', '一直', '一起', '一路', '万元', '上海', '不仅', '不同', '不少', '不断', '不是', '不能', '专业', '专家', '世界', '业务', '中国', '中心', '为了', '主场', '主席', '主要', '举办', '举行', '之一', '之后', '习近平', '了解', '事件', '二线', '互联网', '交流', '产业', '产品', '人们', '人员', '人民', '人民币', '亿元', '今年', '介绍', '他们', '代表', '以上', '以及', '以来', '价格', '企业', '会议', '传统', '位于', '体育', '作为', '作品', '使用', '促进', '俄罗斯', '保护', '信息', '健康', '全国', '全球', '全面', '公司', '公开赛', '共享', '共同', '关于', '关注', '关系', '其中', '其他', '具有', '内容', '冠军', '决定', '决赛', '出现', '分别', '创新', '利用', '制造', '加强', '包括', '北京', '区域', '历史', '去年', '参与', '参加', '双方', '发展', '发布', '发现', '发生', '取得', '叙利亚', '可以', '可能', '台湾', '合作', '同时', '启动', '品牌', '因为', '国内', '国家', '国际', '图表', '地区', '地方', '城市', '基础', '基金', '增加', '增长', '外代', '大学', '夺冠', '如何', '如果', '媒体', '存在', '学习', '学校', '学生', '孩子', '安全', '完成', '实施', '实现', '宣布', '对于', '就是', '展示', '工作', '工程', '已经', '巴黎', '市场', '希望', '带来', '帮助', '平台', '广州', '庆祝', '建立', '建设', '开始', '开展', '开放', '当地', '当天', '当日', '形成', '影响', '影片', '很多', '得到', '德国', '总统', '情况', '意大利', '成为', '成功', '成立', '我们', '我国', '战略', '战胜', '戛纳', '打造', '技术', '投资', '报告', '报道', '拍摄', '持续', '指出', '按照', '接受', '推动', '推进', '提供', '提出', '提升', '提高', '支持', '改革', '政府', '政策', '教育', '数据', '文化', '新华', '新华社', '新疆', '新闻', '方式', '方面', '旅游', '日本', '日电', '时装周', '时间', '显示', '晋级', '最后', '最大', '最终', '有关', '有限公司', '服务', '期间', '未来', '机制', '机构', '来自', '标准', '根据', '模式', '欧新', '欧洲', '正在', '正式', '此次', '死亡', '比赛', '水平', '江苏', '汽车', '没有', '法国', '法新', '活动', '游客', '澳大利亚', '照片', '特别', '特朗普', '环境', '现在', '现场', '球员', '生产', '生态', '生活', '用户', '由于', '电影', '监管', '目前', '目标', '相关', '看到', '研究', '社会', '科技', '积极', '管理', '篮球', '精神', '系统', '组织', '经济', '继续', '综合', '网球', '网络', '美国', '群众', '联合', '联赛', '能力', '能够', '自己', '英国', '英超', '获得', '行业', '行动', '表示', '要求', '规划', '规定', '规模', '解决', '计划', '认为', '记者', '设计', '调查', '资源', '资金', '赛季', '超过', '足球', '路透', '达到', '过程', '近年来', '近日', '还是', '还有', '这一', '这个', '这些', '这是', '这样', '这种', '进一步', '进入', '进行', '选手', '选择', '通过', '造成', '部分', '部门', '重点', '重要', '金融', '铁路', '银行', '锦标赛', '问题', '随着', '集团', '需求', '需要', '非常', '韩国', '项目', '预计', '领域', '风险', '首次', '首都', '香港']\n",
      "input of X's shape is  (87052, 350)\n"
     ]
    }
   ],
   "source": [
    "# corpus = news['content'].apply(lambda x: np.str_(x))\n",
    "print(\"corpus's shape is \", corpus.shape)\n",
    "vectorizer = TfidfVectorizer(max_features = 350, stop_words = [])\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(\"input of X's shape is \", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data's shape is (87052, 350)\n"
     ]
    }
   ],
   "source": [
    "train_data = X.toarray()\n",
    "print(\"train_data's shape is {}\".format(train_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceMapping = {}\n",
    "for index, label in enumerate(set(news['source'])):\n",
    "    if label == \"新华社\":\n",
    "        sourceMapping['新华社'] = 1\n",
    "    else:\n",
    "        sourceMapping[label] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "news['source'] = news['source'].map(sourceMapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data's shape is (87052,)\n"
     ]
    }
   ],
   "source": [
    "test_data = news['source']\n",
    "print(\"test_data's shape is {}\".format(test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, test_input, train_output, test_output = train_test_split(train_data, test_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WDMWDL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\WDMWDL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "x_arr_train = train_input\n",
    "x_arr_test = test_input\n",
    "y_arr_train = train_output.as_matrix()\n",
    "y_arr_test = test_output.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WDMWDL\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, class_weight='balanced').fit(x_arr_train, y_arr_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 当停用词没有应用时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9755327092068232"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_arr_test, y_arr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_arr_test_pred = clf.predict(x_arr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9814698492462312"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_arr_test, y_arr_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9916857070322417"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_arr_test, y_arr_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9865513322389191"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_arr_test, y_arr_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 当停用词应用时 of stopWords = ['nba', 'nn', 'nnn', 'nnnum', 'nnum', 'num', 'numnum', 'numn', '一个', '一些', '一名', '一带', '一次', '一直', '一起', '一路', '万元']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9654815920969502"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_arr_test, y_arr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_arr_test_pred = clf.predict(x_arr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision score and recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9754062362758015"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_arr_test, y_arr_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9867352119827367"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_arr_test, y_arr_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9810380186149236"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_arr_test, y_arr_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17411,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_arr_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17411, 350)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_arr_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with weighted balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9321118832921717\n",
      "0.9972703698648833\n",
      "0.9275196750444276\n",
      "0.9611312068398554\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(x_arr_test, y_arr_test))\n",
    "y_arr_test_pred = clf.predict(x_arr_test)\n",
    "print(precision_score(y_arr_test, y_arr_test_pred))\n",
    "print(recall_score(y_arr_test, y_arr_test_pred))\n",
    "print(f1_score(y_arr_test, y_arr_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 判断是否为抄袭"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 当数据为tdata[index =100]时,判断其为抄袭或不是"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = clf.predict(x_arr_test[index].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index = 100 是抄袭\n"
     ]
    }
   ],
   "source": [
    "if val == y_arr_test[index]:\n",
    "    print(\"index = {} 不是抄袭\".format(index))\n",
    "else:\n",
    "    print(\"index = {} 是抄袭\".format(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=15, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neighbors = 15\n",
    "neighbors_clf = KNeighborsClassifier(n_neighbors, weights = 'distance')\n",
    "neighbors_clf.fit(x_arr_train, y_arr_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 存储模型和导出模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_model_neighbors.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(neighbors_clf, 'my_model_neighbors.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_loaded = joblib.load(\"my_model_neighbors.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### proformance of the k nearest neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WDMWDL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used:  59.82750911699986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WDMWDL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "y_arr_test_pred_neighbors = neighbors_clf.predict(x_arr_test[:400])\n",
    "elapsed = (time.clock() - start)\n",
    "print(\"Time used: \",elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9361702127659575"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_arr_test[:400], y_arr_test_pred_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9750692520775623"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_arr_test[:400], y_arr_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9552238805970149"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_arr_test[:400], y_arr_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型微调 --- 网格搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [{'weights':['uniform', 'distance'], \"n_neighbors\":[2, 5, 10, 15, 20]}]\n",
    "neighbors_clf_grid = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(neighbors_clf_grid, param_grid, cv = 5, scoring = ['precision', 'recall', 'f1'], refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(x_arr_train, y_arr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model construction with Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(x_arr_train[1:45000,:], y_arr_train[1:45000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_evaluation(clf):\n",
    "#     print(\"model's score is {}\".format(clf.score(x_arr_test, y_arr_test)))\n",
    "    y_arr_test_pred = clf.predict(x_arr_test)\n",
    "    print(\"precision is {}\".format(precision_score(y_arr_test, y_arr_test_pred)))\n",
    "    print(\"recall score is {}\".format(recall_score(y_arr_test, y_arr_test_pred)))\n",
    "    print(\"f1 is {}\".format(f1_score(y_arr_test, y_arr_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model's score is 0.8464189305611395\n",
      "precision is 0.9943319226118501\n",
      "recall score is 0.835046966235085\n",
      "f1 is 0.9077549330757555\n"
     ]
    }
   ],
   "source": [
    "performance_evaluation(gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model construction with random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=30, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=1,max_depth=30, random_state=0)\n",
    "clf.fit(x_arr_train, y_arr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model's score is 0.9854689564068693\n",
      "precision is 0.9911919396742919\n",
      "recall score is 0.9927646610814927\n",
      "f1 is 0.9919776770143006\n"
     ]
    }
   ],
   "source": [
    "performance_evaluation(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model construction with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WDMWDL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consuming time is 14.094820975999937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WDMWDL\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\WDMWDL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "start = time.clock()\n",
    "clf = SVC(gamma='auto', random_state=42, max_iter=500, kernel ='linear')\n",
    "clf.fit(x_arr_train[1:10000], y_arr_train[1:10000])\n",
    "elapse = time.clock() - start\n",
    "print(\"consuming time is {}\".format(elapse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision is 0.9724523092369478\n",
      "recall score is 0.9835618177202335\n",
      "f1 is 0.9779755143253818\n"
     ]
    }
   ],
   "source": [
    "performance_evaluation(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
